{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6440da",
   "metadata": {},
   "source": [
    "#### Setting up game configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc45c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "import random # for random actions\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Open AI Gym dependencies\n",
    "import gymnasium as gym\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box # for random actions and nxm for random observation space (frames)\n",
    "import cv2\n",
    "\n",
    "# Stable Baselines3 dependencies\n",
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Optimizer\n",
    "import optuna "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb4a6d9",
   "metadata": {},
   "source": [
    "### Converting it to a Gym Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed19803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game configuration : Take Cover configuration file\n",
    "config = 'github_vizdoom_repo/ViZDoom/scenarios/take_cover_lev1.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174cbeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Vizdoom OpenAI Gym Environment\n",
    "class VizDoomGym(Env):\n",
    "    def __init__(self, render_mode = False, config = config): # By default, rendering is disabled\n",
    "        # Inheriting from the Env class\n",
    "        super().__init__()\n",
    "        # Setup game\n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config(config) \n",
    "\n",
    "        # Rendering mode : if unabled, the game will not be displayed but the training will be faster\n",
    "        if render_mode == False:\n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "\n",
    "        # Start the game\n",
    "        self.game.init()\n",
    "        \n",
    "        # In order to get the game frame size, run a dummy demo and get the screen buffer shape  with game.get_state().screen_buffer.shape\n",
    "        self.observation_space = Box(low=0, high=255, shape=(100, 160, 1), dtype = np.uint8)\n",
    "        # Action space\n",
    "        self.action_space = Discrete(2) # left, right\n",
    "        self.current_step = 0\n",
    "\n",
    "\n",
    "    # Defining how to make a step in the env\n",
    "    def step(self, action):\n",
    "        actions = np.identity(2, dtype=np.uint8) # Possible actions [left, right]\n",
    "        reward = self.game.make_action(actions[action], 4) # Defyining the frame skip parameter to 4\n",
    "\n",
    "        # Check if the frames are over\n",
    "        if self.game.get_state():\n",
    "            state = self.game.get_state().screen_buffer\n",
    "            obs = self.grayscale(state)\n",
    "            health = self.game.get_state().game_variables[0]\n",
    "            terminated = self.game.is_episode_finished()\n",
    "            truncated = self.current_step >= 2100  # Max steps\n",
    "            info = {\"health\": health}\n",
    "        else: # Default zeros observation\n",
    "            obs = np.zeros(self.observation_space.shape, dtype=np.uint8)\n",
    "            terminated = True\n",
    "            truncated = False\n",
    "            info = {} # Empty info: no 0 beacuse the API doesn't allow it\n",
    "\n",
    "        self.current_step += 1\n",
    "        return obs, reward, terminated, truncated, info # Changed parameters order according to Gymnasium API\n",
    "    \n",
    "    def render():\n",
    "        pass\n",
    "    \n",
    "    # What appens when starting a new episode\n",
    "    def reset(self, seed = None, options = None):\n",
    "        super().reset(seed=seed)\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        obs = self.grayscale(state)\n",
    "        info = {\"health\": self.game.get_state().game_variables[0]}\n",
    "        self.current_step = 0\n",
    "\n",
    "        return obs, info\n",
    "\n",
    "    # Grayscale and resize the frames in order to reduce the observation space\n",
    "    ## POSSIBLE IMPROVEMENT : CUT OFF BOTTOM PART OF THE IMAGE WHERE THERE IS NO USEFUL INFORMATION\n",
    "    def grayscale(self, observation):\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY) # moveaxis moves the first element (0) to last position (-1)\n",
    "        resize = cv2.resize(gray, (160, 100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100,160, 1))\n",
    "        return state\n",
    "\n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45fd179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pass to see if the environment works\n",
    "env_checker.check_env(env=VizDoomGym())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62532fc9",
   "metadata": {},
   "source": [
    "### Setting up Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a97276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}.zip'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3f692",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_DeadlyCorridor'\n",
    "OPT_DIR = './opt/opt_DeadlyCorridor'\n",
    "LOG_DIR = './logs/log_DeadlyCorridor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf49e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path = CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f872866",
   "metadata": {},
   "source": [
    "### Hyperparameters Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e0460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function to test hyperparameters\n",
    "def optimize_ppo(trial):\n",
    "    return {\n",
    "        'n_steps': trial.suggest_int('n_steps', 2048, 8192, step = 64), # number of frames used in a single training step (must be multiple of 64)\n",
    "        'gamma': trial.suggest_float('gamma', 0.8, 0.9999, log = True), # discount factor\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-4, log = True),\n",
    "        'clip_range': trial.suggest_float('clip_range', 0.1, 0.4),\n",
    "        'gae_lambda': trial.suggest_float('gae_lambda', 0.8, 0.99)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a training loop and return the mean reward\n",
    "def optimize_agent(trial):\n",
    "    try:\n",
    "        model_params = optimize_ppo(trial) # set of hyperparameters to test\n",
    "\n",
    "        # Create new env\n",
    "        env = VizDoomGym(config=config)\n",
    "        env = Monitor(env, LOG_DIR)\n",
    "        env = DummyVecEnv([lambda: env])\n",
    "        env = VecFrameStack(env, 4, channels_order='last')\n",
    "\n",
    "        # Set up, train and evaluatethe PPO model\n",
    "        model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=0, **model_params)\n",
    "        model.learn(total_timesteps=100000)\n",
    "        \n",
    "        mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=5)\n",
    "        env.close()\n",
    "\n",
    "        # Save the best model \n",
    "        SAVE_PATH = os.path.join(OPT_DIR, 'trial_{}_best_model'.format(trial.number))\n",
    "        model.save(SAVE_PATH)\n",
    "\n",
    "        return mean_reward\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return -1000 # Return a very low reward if training fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c414f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin an optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_agent, n_trials=100, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17397fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters combo: \", study.best_params)\n",
    "print(\"Best trial: \", study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d142340",
   "metadata": {},
   "source": [
    "### Fine-Tuning the best Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b58d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90571c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate PPO model\n",
    "model = PPO('CnnPolicy', # policy type -> CnnPolicy since we are working on image frames\n",
    "            env,\n",
    "            tensorboard_log=LOG_DIR,\n",
    "            verbose=1,\n",
    "            learning_rate=study.best_params['learning_rate'],\n",
    "            n_steps=study.best_params['n_steps'], \n",
    "            clip_range=study.best_params['clip_range'],\n",
    "            gamma= study.best_params['gamma'],\n",
    "            gae_lambda=study.best_params['gae_lambda']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a02120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps = 400000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f072c",
   "metadata": {},
   "source": [
    "### Testing the trained agent on real-time game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4536135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the best model from disk\n",
    "model = PPO.load(\"./train/train_basic/best_model_400000.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(render_mode= True) # rendered-env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73063bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385afa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
